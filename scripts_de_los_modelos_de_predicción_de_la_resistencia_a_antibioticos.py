# -*- coding: utf-8 -*-
"""SCRIPTS DE LOS MODELOS DE PREDICCIÓN DE LA RESISTENCIA A ANTIBIOTICOS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dzbMBYC1OiWbDzgd3ro_CjN13iykRJMw
"""

#VALIDATION CURVES

  #IMPORTAR LIBRERIAS NECESARIAS

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.model_selection import validation_curve


 #CARGAR EL CONJUNTO DE DATOS

data = pd.read_csv('/content/drive/MyDrive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/ALELOS AL 100/CIP_100_PR_TEST.csv')
#data.describe()
#print(data)

  #PREPROCESAMIENTO DE LOS DATOS

#Eliminar valores perdidos  

data_na = data.dropna(axis=0)
print(data_na)

#Convertir las características a variables binarias

lista = data_na.drop('CIP', axis=1)
datadum = pd.get_dummies(lista.astype(str))
print(datadum)

  #Eliminar columnas duplicadas

for col in datadum.columns: 
  if col[-2:] == '_0':
    print(col)
    del(datadum[col])

print(datadum.columns)
print(datadum.shape)

  #DIVISIÓN DE DATOS

#Definir variables independientes (carateristicas) y dependientes (fenotipo)

X = datadum.values

y= data_na['CIP'].values 

#Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%) de forma estratificada segun el fenotipo

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, stratify= y, random_state=42)
print("Conjunto de prueba: ", y_test)

#Inicializar variables según el algoritmo de predicción

lr = LogisticRegression(penalty='l1', solver='saga')  #Regresión logística utilizado regularización lasso
#lr = LogisticRegression(solver='saga')   Regresión logística
lscv =LinearSVC(penalty='l1', dual=False, random_state=42) 
svm = SVC(kernel='linear', probability=True)  #SVM utilizado regularización lasso
skf = StratifiedKFold(n_splits=10)  #SVM


#Definir el rango de valores del parámetro C a ensayar

param_range = [0.0001, 0.001, 0.01,  0.1, 1.0, 10, 100, 1000]

#Generar curva de validación

train_scores, test_scores = validation_curve(lr, X=X_train, y=y_train, param_name='C', param_range=param_range, cv=skf)

train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

#Generar gráfico de la curva

plt.plot(param_range, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')
plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')

plt.plot(param_range, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')
plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')

plt.grid()
plt.xscale('log')
plt.legend(loc='lower right')
plt.xlabel('Parameter C')
plt.ylabel('Accuracy')
plt.ylim([0.1, 1.1])
plt.show()

#MODELOS DE PREDICCIÓN UTILIZANDO ELIMINACION RECURSIVA DE CARACTERISTICAS Y SUPPORT VECTOR MACHINE

                         #IMPORTAR LIBRERIAS NECESARIAS

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.model_selection import GridSearchCV
from pandas import ExcelWriter
from sklearn.feature_selection import RFECV
from sklearn.svm import LinearSVC
from sklearn.svm import SVC


                         #CARGAR CONJUNTO DE DATOS

data = pd.read_csv('/content/drive/MyDrive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/ALELOS 97/MER_97_TEST_PR.csv')
#data.describe()
#print(data)

                       #PREPROCESAMIENTO DE LOS DATOS

  #Eliminar valores perdidos

data_na = data.dropna(axis=0)
print(data_na)


  #Convertir las características a variables binarias

lista = data_na.drop('MER', axis=1)
print ('lista: ', lista)
datadum = pd.get_dummies(lista.astype(str))
print('datadum: ', datadum)

  #Eliminar columnas duplicadas 

for col in datadum.columns: 
  if col[-2:] == '_0':
    print(col)
    del(datadum[col])

print('datadum columns',datadum.columns)
print('datadum shape:', datadum.shape)

                        #DIVISIÓN DE DATOS

  #Definir variables independientes (carateristicas) y dependientes (fenotipo)

X = datadum.values

y= data_na['MER'].values 

  #Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%) de forma estratificada segun el fenotipo

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, stratify= y, random_state=42)
print("Conjunto de prueba: ", y_test)





                                #ENTRENAR MODELO


#Inicialiar variables

skf = StratifiedKFold(n_splits=10)
svm = SVC(kernel='linear', probability=True, C=0.01)  #Utilizar valor del parametro C obtenido de la curva de validación

svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
print(accuracy_score(y_test, y_pred))
print(accuracy_score(y_train, svm.predict(X_train)))

 #Selección de características mediante eliminación recursiva de características.

rfecv = RFECV(estimator=svm, cv=skf, scoring='accuracy')
rfecv.fit(X_train, y_train)
y_rfecv = rfecv.predict(X_test)

print('Optimal features :', rfecv.n_features_)
print('Best features: ', datadum.columns[rfecv.support_])

feature_impo = pd.DataFrame(datadum.columns[rfecv.support_])
writer = ExcelWriter('/content/drive/My Drive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/FEATURES/FEATURES_SVM_REFCV.xls')
feature_impo.to_excel(writer, 'Hoja de datos')
writer.save()

  #Mantener las caracteristicas seleccionadas como importantes

X_train_rfecv = rfecv.transform(X_train)
X_test_rfecv = rfecv.transform(X_test)
print('X transformado', X_train_rfecv.shape)

                            #AJUSTE DE HIPERPARÁMETROS

  #Definir el rango de valores e hiperparámetros para la optimización

parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'poly', 'rbf']}

  #Entrenar el modelo para obtener los mejores hiperparámetros

model = GridSearchCV(svm, parameters, cv=skf)
model.fit(X_train_rfecv, y_train)
print('Parametros: ', model.best_params_)
print('Mejor puntaje', model.best_score_)
print(model.best_estimator_)

y_predicted = model.predict(X_test_rfecv)

print('Accuracy test', accuracy_score(y_test, y_predicted))
print('Accuracy training', accuracy_score(y_train, model.predict(X_train_rfecv)))

# Matriz de confusion y reporte de clasificacion del entrenamiento

cm_train =confusion_matrix(y_train, model.predict(X_train_rfecv))
print(cm_train)

print('Class report train: ', classification_report(y_train, model.predict(X_train_rfecv)))

# Matriz de confusion y reporte de clasificacion de prueba

cm =confusion_matrix(y_test, y_predicted)
print(cm)

print('Class report test: ', classification_report(y_test, y_predicted))

ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted');ax.set_ylabel('True'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['Sensible','Resistente']); ax.yaxis.set_ticklabels(['Sensible', 'Resistente'])

#MODELOS DE PREDICCIÓN UTILIZANDO REGULARIZACION LASSO Y SUPPORT VECTOR MACHINE

                            #IMPORTAR LIBRERIAS NECESARIAS

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.metrics as metrics
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.model_selection import GridSearchCV
from pandas import ExcelWriter
from sklearn.feature_selection import RFECV
from sklearn.svm import LinearSVC
from sklearn.svm import SVC

                              #CARGAR DATOS

data = pd.read_csv('/content/drive/MyDrive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/ALELOS 97/IMI_97_TEST_PR.csv')
#data.describe()
#print(data)

                       #PREPROCESAMIENTO DE LOS DATOS

  #Eliminar valores perdidos

data_na = data.dropna(axis=0)
print(data_na)

  #Convertir las características a variables binarias

lista = data_na.drop('IMI', axis=1)
print ('lista: ', lista)
datadum = pd.get_dummies(lista.astype(str))
print('datadum: ', datadum)

  #Eliminar columnas duplicadas
for col in datadum.columns: 
  if col[-2:] == '_0':
    print(col)
    del(datadum[col])

print('datadum columns',datadum.columns)
print('datadum shape:', datadum.shape)

                                       #DIVISIÓN DE DATOS
                                       
  #Definir variables independientes (carateristicas) y dependientes (fenotipo)

X = datadum.values

y= data_na['IMI'].values 

  #Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%) de forma estratificada segun el fenotipo

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, stratify= y, random_state=42)
print("Conjunto de prueba: ", y_test)
                                      

                                #ENTRENAR MODELO

  #Inicializar variables

lscv =LinearSVC(penalty='l1', dual=False, random_state=42, C=0.1)  #Utilizar valor del parametro C obtenido de la curva de validación
skf = StratifiedKFold(n_splits=10)

lscv.fit(X_train, y_train)
y_pred = lscv.predict(X_test)
print(accuracy_score(y_test, y_pred))
print(accuracy_score(y_train, lscv.predict(X_train)))

  #Selección de características mediante regularizacion lasso

sel_lasso = SelectFromModel(lscv)
sel_lasso.fit(X_train, y_train)
criterio = sel_lasso.get_support()
#print(criterio_feat)
my_df = pd.DataFrame(datadum.columns, [criterio])
#print(my_df)

writer = ExcelWriter('/content/drive/My Drive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/FEATURES_SVM_lasso.xls')
my_df.to_excel(writer, 'Hoja de datos')
writer.save()

  #Mantener las caracteristicas seleccionadas como importantes
X_train_lasso = sel_lasso.transform(X_train)
X_test_lasso = sel_lasso.transform(X_test)

                            #AJUSTE DE HIPERPARÁMETROS

  #Inicializar variables

svm = SVC(probability=True, random_state=42)

  #Definir el rango de valores e hiperparámetros para la optimización

parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'poly', 'rbf']}

  #Entrenar el modelo para obtener los mejores hiperparámetros

model_lasso = GridSearchCV(svm, parameters, cv=skf)
model_lasso.fit(X_train_lasso, y_train)
print('Parametros: ', model_lasso.best_params_)
print('Mejor puntaje', model_lasso.best_score_)
print(model_lasso.best_estimator_)

y_pred_lasso = model_lasso.predict(X_test_lasso)
print('Accuracy test', accuracy_score(y_test, y_pred_lasso))
print('Accuracy training', accuracy_score(y_train, model_lasso.predict(X_train_lasso)))

# Matriz de confusion y reporte de clasificacion del entrenamiento

cm_train =confusion_matrix(y_train, model_lasso.predict(X_train_lasso))
print(cm_train)
print('Class report train: ', classification_report(y_train, model_lasso.predict(X_train_lasso)))

# Matriz de confusion y reporte de clasificacion de prueba

cm =confusion_matrix(y_test, y_pred_lasso)
print(cm)
print(classification_report(y_test, y_pred_lasso))
print('Class report test: ', classification_report(y_test, y_pred_lasso))

ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax);

#labels, title and ticks
ax.set_xlabel('Predicted');ax.set_ylabel('True'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['Sensible', 'Resistente']); ax.yaxis.set_ticklabels(['Sensible','Resistente'])

#MODELOS DE PREDICCION UTILIZANDO ELIMINACION RECURSIVA DE CARACTERISTICAS Y REGRESION LOGISTICA

  #IMPORTAR LIBRERIAS NECESARIAS

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.metrics as metrics
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from pandas import ExcelWriter
from sklearn.feature_selection import RFECV


                      #CARGAR CONJUNTO DE DATOS

data = pd.read_csv('/content/drive/MyDrive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/ALELOS AL 95/TGCEUCAST_95_TEST_PR.csv')
#data.describe()
#print(data)
 
                       #PREPROCESAMIENTO DE LOS DATOS

#Eliminar valores perdidos

data_na = data.dropna(axis=0)
print(data_na)

#Convertir las características a variables binarias

lista = data_na.drop('TGC_EUCAST', axis=1)
datadum = pd.get_dummies(lista.astype(str))
print(datadum)

  #Eliminar columnas duplicadas
  
for col in datadum.columns: 
  if col[-2:] == '_0':
    print(col)
    del(datadum[col])

print(datadum.columns)
print(datadum.shape)

                      #DIVISIÓN DE DATOS

#Definir variables independientes (carateristicas) y dependientes (fenotipo)

X = datadum.values

y= data_na['TGC_EUCAST'].values

#Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%) de forma estratificada segun el fenotipo

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, stratify= y, random_state=42)
print("Valor a predecir: ", y_test)


                #ENTRENAR MODELO

  #Inicialiar variables

skf = StratifiedKFold(n_splits=10)
lr = LogisticRegression(C=1) #Utilizar valor del parametro C obtenido de la curva de validación

lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)
print(accuracy_score(y_test, y_pred))
print(accuracy_score(y_train, lr.predict(X_train)))


 #Selección de características mediante eliminación recursiva de características.

rfecv = RFECV(estimator=lr, cv=skf, scoring='accuracy')
rfecv.fit(X_train, y_train)
y_rfecv = rfecv.predict(X_test)

print('Optimal features :', rfecv.n_features_)
print('Best features: ', datadum.columns[rfecv.support_])

feature_impo = pd.DataFrame(datadum.columns[rfecv.support_])
writer = ExcelWriter('/content/drive/My Drive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/FEATURES/FEATURES_RFECV.xls')
feature_impo.to_excel(writer, 'Hoja de datos')
writer.save()

  #Mantener las caracteristicas seleccionadas como importantes

X_train_rfecv = rfecv.transform(X_train)
X_test_rfecv = rfecv.transform(X_test)
print('X trans', X_train_rfecv.shape)

                    #AJUSTE DE HIPERPARÁMETROS
  
  #Definir el rango de valores e hiperparámetros para la optimización

parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}

 #Entrenar el modelo para obtener los mejores hiperparámetros

model = GridSearchCV(lr, parameters, cv=skf)
model.fit(X_train_rfecv, y_train)
print('Parametros: ', model.best_params_)
print('Mejor puntaje', model.best_score_)
print(model.best_estimator_)

y_predicted = model.predict(X_test_rfecv)

print('Accuracy test', accuracy_score(y_test, y_predicted))
print('Accuracy training', accuracy_score(y_train, model.predict(X_train_rfecv)))

  #Matriz de confusion y reporte de clasificacion training

cm_train =confusion_matrix(y_train, model.predict(X_train_rfecv))
print(cm_train)
print('Class report train: ', classification_report(y_train, model.predict(X_train_rfecv)))

# Matriz de confusion y reporte de clasificacion de test

cm =confusion_matrix(y_test, y_predicted)
print(cm)
print('Class report test: ', classification_report(y_test, y_predicted))

ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted');ax.set_ylabel('True'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['Sensible','Resistente']); ax.yaxis.set_ticklabels(['Sensible', 'Resistente'])

#MODELOS DE PREDICCION UTILIZANDO REGULARIZACIÓN LASSO Y REGRESION LOGISTICA

  #IMPORTAR LIBRERIAS NECESARIAS

import pandas as pd
import numpy as np
import sklearn.metrics as metrics
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold, KFold
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import SelectFromModel
from pandas import ExcelWriter


                              #CARGAR DATOS

data = pd.read_csv('/content/drive/MyDrive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/ALELOS AL 100/TGCEUCAST_100_PR_TEST.csv')
#data.describe()
#print(data)

                       #PREPROCESAMIENTO DE LOS DATOS

#Eliminar missing values

data_na = data.dropna(axis=0)
print(data_na)

#Convertir las características a variables binarias

lista = data_na.drop('TGC_EUCAST', axis=1)
datadum = pd.get_dummies(lista.astype(str))
print(datadum)

#Eliminar columnas duplicadas

for col in datadum.columns: 
  if col[-2:] == '_0':
    print(col)
    del(datadum[col])

print(datadum.columns)
print(datadum.shape)

                       #DIVISIÓN DE DATOS
#Definir variables independientes (carateristicas) y dependientes (fenotipo)

X = datadum.values

y= data_na['TGC_EUCAST'].values 

#Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%) de forma estratificada segun el fenotipo

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, stratify= y, random_state=42)
print("Conjunto de prueba: ", y_test)


                                #ENTRENAR MODELO

#Selección de características mediante regularización L1

skf = StratifiedKFold(n_splits=10)
lr = LogisticRegression(penalty='l1', solver='saga', C=0.1) #Utilizar valor del parametro C obtenido de la curva de validación
lr.fit(X_train, y_train)

sel_lasso = SelectFromModel(lr)
sel_lasso.fit(X_train, y_train)
criterio = sel_lasso.get_support()
#print(criterio_feat)
my_df = pd.DataFrame(datadum.columns, [criterio])
#print(my_df)

writer = ExcelWriter('/content/drive/My Drive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/FEATURES_lasso.xls')
my_df.to_excel(writer, 'Hoja de datos')
writer.save()

X_train_lasso = sel_lasso.transform(X_train)
X_test_lasso = sel_lasso.transform(X_test)

                            #AJUSTE DE HIPERPARÁMETROS

  #Definir el rango de valores e hiperparámetros para la optimización

parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}

 #Entrenar el modelo para obtener los mejores hiperparámetros

lr = LogisticRegression(solver='saga')

model_lasso = GridSearchCV(lr, parameters, cv=skf)
model_lasso.fit(X_train_lasso, y_train)
print('Parametros: ', model_lasso.best_params_)
print('Mejor puntaje', model_lasso.best_score_)
print(model_lasso.best_estimator_)

y_pred_lasso = model_lasso.predict(X_test_lasso)
print('Accuracy test', accuracy_score(y_test, y_pred_lasso))
print('Accuracy training', accuracy_score(y_train, model_lasso.predict(X_train_lasso)))

  #Matriz de confusion y reporte de clasificacion de training

cm_train =confusion_matrix(y_train, model_lasso.predict(X_train_lasso))
print(cm_train)

print('Class report train: ', classification_report(y_train, model_lasso.predict(X_train_lasso)))

  #Matriz de confusion y reporte de clasificacion de test

cm =confusion_matrix(y_test, y_pred_lasso)
print(cm)
print(classification_report(y_test, y_pred_lasso))

ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted');ax.set_ylabel('True'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['Sensible', 'Resistente']); ax.yaxis.set_ticklabels(['Sensible','Resistente'])

#MODELOS DE PREDICCIÓN UTILIZANDO ELIMINACION RECURSIVA DE CARACTERISTICAS Y RANDOM FOREST

  #IMPORTAR LIBRERIAS NECESARIAS

import pandas as pd
import numpy as np
import sklearn.metrics as metrics
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold, KFold
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV
import statsmodels.api as sm
from pandas import ExcelWriter
from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestClassifier

                              #CARGAR DATOS

data = pd.read_csv('/content/drive/My Drive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/PRE AU/TGCEUCAST_PA_TEST_PR.csv')
#data.describe()
#print(data)
 
                       #PREPROCESAMIENTO DE LOS DATOS

  #Eliminar valores perdidos

data_na = data.dropna(axis=0)
print(data_na)

  #Convertir las características a variables binarias 

lista = data_na.drop('TGC_EUCAST', axis=1)
datadum = pd.get_dummies(lista.astype(str))
print(datadum)

  #Eliminar columnas duplicadas

for col in datadum.columns: 
  if col[-2:] == '_0':
    print(col)
    del(datadum[col])

print(datadum.columns)
print(datadum.shape)

                                      #DIVISIÓN DE DATOS

  #Definir variables independientes (carateristicas) y dependientes (fenotipo)

X = datadum.values

y= data_na['TGC_EUCAST'].values 

  #Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%) de forma estratificada segun el fenotipo

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, stratify= y, random_state=42)
print("Valor a predecir: ", y_test)



                                #ENTRENAR MODELO
  #Inicialiar variables

skf = StratifiedKFold(n_splits=10)
Ramfor = RandomForestClassifier(random_state=42)
Ramfor.fit(X_train, y_train)

y_pred = Ramfor.predict(X_test)
print(accuracy_score(y_test, y_pred))
print(accuracy_score(y_train, Ramfor.predict(X_train)))

 #Selección de características mediante eliminación recursiva de características.

rfecv = RFECV(estimator=Ramfor, cv=skf, scoring='accuracy')

rfecv.fit(X_train, y_train)
y_rfecv = rfecv.predict(X_test)

print('Optimal features :', rfecv.n_features_)
print('Best features: ', datadum.columns[rfecv.support_])

feature_impo = pd.DataFrame(datadum.columns[rfecv.support_])
writer = ExcelWriter('/content/drive/My Drive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/FEATURES/RF__MULREFCV.xls')
feature_impo.to_excel(writer, 'Hoja de datos')
writer.save()

  #Mantener las caracteristicas seleccionadas como importantes

X_train_rfecv = rfecv.transform(X_train)
X_test_rfecv = rfecv.transform(X_test)
print('X trans', X_train_rfecv.shape)

                            #AJUSTE DE HIPERPARÁMETROS

  #Definir el rango de valores e hiperparámetros para la optimización

parameters = {'max_depth' : [2, 4, 6], 'min_samples_leaf': [1, 2, 4], 'min_samples_split' : [2, 5, 10], 'n_estimators': [50, 100, 200, 400], 'max_features': ['sqrt', 'auto']}

 #Entrenar el modelo para obtener los mejores hiperparámetros

model = GridSearchCV(Ramfor, parameters, cv=skf)
model.fit(X_train_rfecv, y_train)
print('Parametros: ', model.best_params_)
print('Mejor puntaje', model.best_score_)
print(model.best_estimator_)

y_predicted = model.predict(X_test_rfecv)

print('Accuracy test', accuracy_score(y_test, y_predicted))
print('Accuracy training', accuracy_score(y_train, model.predict(X_train_rfecv)))

  #Matriz de confusion y reporte de clasificacion training

cm_train =confusion_matrix(y_train, model.predict(X_train_rfecv))
print(cm_train)

print('Class report train: ', classification_report(y_train, model.predict(X_train_rfecv)))

  #Matriz de confusion y reporte de clasificacion test

cm =confusion_matrix(y_test, y_predicted)
print(cm)

print(classification_report(y_test, y_predicted))


ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted');ax.set_ylabel('True'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['Sensible','Resistente']); ax.yaxis.set_ticklabels(['Sensible', 'Resistente'])

#MODELOS DE PREDICCIÓN UTILIZANDO FEATURE IMPORTANCE Y RANDOM FOREST

  #IMPORTAR LIBRERIAS NECESARIAS

import pandas as pd
import numpy as np
import sklearn.metrics as metrics
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.metrics import scorer
from sklearn.model_selection import StratifiedKFold, KFold
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV
from pandas import ExcelWriter
from sklearn.ensemble import RandomForestClassifier

                              #CARGAR DATOS

data = pd.read_csv('/content/drive/My Drive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/ALELOS AL 95/TGCEUCAST_95_TEST_PR.csv')
#data.describe()
#print(data)

                       #PREPROCESAMIENTO DE LOS DATOS

  #Eliminar valores perdidos

data_na = data.dropna(axis=0)
#print(data_na)

  #Convertir las características a variables binarias 

lista = data_na.drop('TGC_EUCAST', axis=1)
datadum = pd.get_dummies(lista.astype(str))
#print(datadum)

  #Eliminar columnas duplicadas
  
for col in datadum.columns: 
  if col[-2:] == '_0':
    #print(col)
    del(datadum[col])

#print(datadum.columns)
#print(datadum.shape)

                                      #DIVISIÓN DE DATOS


  #Definir variables independientes (carateristicas) y dependientes (fenotipo)

X = datadum.values

y= data_na['TGC_EUCAST'].values 

  #Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%) de forma estratificada segun el fenotipo

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, stratify= y, random_state=42)
print("Valor a predecir: ", y_test)
print('X_train shape :', X_train.shape)


                                #ENTRENAR MODELO

  #Inicialiar variables

skf = StratifiedKFold(n_splits=10)
Ramfor = RandomForestClassifier(random_state=42)
Ramfor.fit(X_train, y_train)

 #Selección de características mediante Feature Importance

characteristic = datadum.columns
importances = Ramfor.feature_importances_
#print(importances)
# get importance
characteristics_importances = [(characteristic, round(importance, 2)) for characteristic, importance in zip(characteristic, importances)]
characteristics_importances = sorted(characteristics_importances, key = lambda x: x[1], reverse = True)
#[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in characteristics_importances];
print(characteristics_importances)

my_df = pd.DataFrame(datadum.columns, [importances])
#print(my_df)
writer = ExcelWriter('/content/drive/My Drive/MATRICES PR/CONJUNTOS DE DATOS_MODELO PR/FEATURES/RF_FEATIMPO.xls')
my_df.to_excel(writer, 'Hoja de datos')
writer.save()

for dat in characteristics_importances:
  if dat[1] < 0.01:
    del(datadum[dat[0]])
print(dat)
print(X_train.shape)


                            #AJUSTE DE HIPERPARÁMETROS

  #Definir el rango de valores e hiperparámetros para la optimización

parameters = {'max_depth' : [2, 4, 6], 'min_samples_leaf': [1, 2, 4], 'min_samples_split' : [2, 5, 10], 'n_estimators': [50, 100, 200, 400], 'max_features': ['sqrt', 'auto']}
 
 #Entrenar el modelo para obtener los mejores hiperparámetros

model = GridSearchCV(Ramfor, parameters, cv=skf)
model.fit(X_train, y_train)
print('Parametros: ', model.best_params_)
print('Mejor puntaje', model.best_score_)
print(model.best_estimator_)

y_predicted = model.predict(X_test)

print('Accuracy test: ', accuracy_score(y_test, y_predicted))
print('Accuracy training: ', accuracy_score(y_train, model.predict(X_train)))

  #Matriz de confusion y reporte de clasificacion training

cm_train =confusion_matrix(y_train, model.predict(X_train))
print(cm_train)

print('Class report train: ', classification_report(y_train, model.predict(X_train)))

  #Matriz de confusion y reporte de clasificacion test

cm =confusion_matrix(y_test, y_predicted)
print(cm)

print(classification_report(y_test, y_predicted))

ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted');ax.set_ylabel('True'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['Sensible','Resistente']); ax.yaxis.set_ticklabels(['Sensible', 'Resistente'])